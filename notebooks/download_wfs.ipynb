{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download WFS Data\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/lalgonzales/datasets/blob/main/notebooks/download_wfs.ipynb)\n",
    "\n",
    "This notebook is used to generate the datasets shared in this repository. It demonstrates how to download data from a Web Feature Service (WFS) and save it in various formats such as Shapefile, GeoJSON, and GPKG. The downloaded shapefile data is then compressed into ZIP files for easy distribution.\n",
    "\n",
    "## Explore and Download Data\n",
    "\n",
    "Feel free to explore and download the data using this notebook on your local machine or in Google Colab. You can modify the notebook to suit your needs and generate the datasets as required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install owslib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "import warnings\n",
    "from owslib.wfs import WebFeatureService\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output vector directory if it doesn't exist\n",
    "output_dir = 'vector'\n",
    "os.makedirs(output_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the WFS capabilities\n",
    "url = \"https://geoserver.icf.gob.hn/icf/wfs\"\n",
    "wfs = WebFeatureService(url=url, version='1.1.0')\n",
    "\n",
    "# Create a list of the layers available\n",
    "layers = list(wfs.contents)\n",
    "layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary naming the layers and their titles\n",
    "layer_dict = {}\n",
    "for layer in layers:\n",
    "    title = wfs[layer].title\n",
    "    layer_dict[title] = layer\n",
    "layer_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the list of layers to download\n",
    "layer_list = [\n",
    "    \"Limite_HN\", # National boundary of Honduras\n",
    "    \"adef\", # Deforestation alerts from Global Forest Watch\n",
    "    \"areas_asignadas\", #\n",
    "    \"areas_protegidas\", # Declared protected areas\n",
    "    \"areas_protegidas_propuesta\", # Proposed protected areas\n",
    "    \"m1102va001970_hn\", # Departametnal boundaries\n",
    "    \"m1103va002001_hn\", # Municipal boundaries,\n",
    "    \"m1104vA002001_HN\", # Village boundaries\n",
    "    \"microcuencas_declaradas\", # Declared watersheds\n",
    "    \"planes_de_manejo_aprobados\", # Approved forest management plans\n",
    "    \"regiones_forestales_icf\", # ICF forest regions\n",
    "    \"reservas_biosfera\", # Biosphere reserves\n",
    "    \"reservas_naturales_privadas\", # Private nature reserves\n",
    "    \"vida_silvestre\", # Wildlife sites\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to rename layers\n",
    "def rename_layer(layer):\n",
    "    layer_names = {\n",
    "        'adef': 'alertas_deforestacion',\n",
    "        'm1102va001970_hn': 'departamentos_hn',\n",
    "        'm1103va002001_hn': 'municipios_hn',\n",
    "        'm1104vA002001_HN': 'aldeas_hn'\n",
    "    }\n",
    "    return layer_names.get(layer, layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if layers exist in WFS\n",
    "available_layers = wfs.contents.keys()\n",
    "missing_layers = [layer for layer in layer_list if layer_dict[layer] not in available_layers]\n",
    "\n",
    "if missing_layers:\n",
    "    print(f\"Warning: The following layers are missing in the WFS and will be skipped: {missing_layers}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the layers as geojson files\n",
    "print(\"Downloading layers...\")\n",
    "for layer in layer_list:\n",
    "    if layer_dict[layer] not in available_layers:\n",
    "        continue\n",
    "    try:\n",
    "        response = wfs.getfeature(typename=layer_dict[layer], outputFormat=\"json\")\n",
    "        renamed_layer = rename_layer(layer)\n",
    "        with open(os.path.join(output_dir, f\"{renamed_layer}.geojson\"), \"wb\") as file:\n",
    "            file.write(response.read())\n",
    "        print(f\"{renamed_layer} downloaded as GeoJSON\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing layer {layer}: {e}\")\n",
    "\n",
    "print(f\"Downloaded {len(layer_list) - len(missing_layers)} layers as GeoJSON files\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the layers as gkpg files\n",
    "print(\"Downloading layers...\")\n",
    "for layer in layer_list:\n",
    "    if layer_dict[layer] not in available_layers:\n",
    "        continue\n",
    "    try:\n",
    "        response = wfs.getfeature(typename=layer_dict[layer], outputFormat=\"json\")\n",
    "        gdf = gpd.read_file(response)\n",
    "        renamed_layer = rename_layer(layer)\n",
    "        # Save temporary GPKG\n",
    "        gpkg_path = os.path.join(output_dir, f\"{renamed_layer}.gpkg\")\n",
    "        gdf.to_file(gpkg_path, driver=\"GPKG\")\n",
    "        print(f\"{renamed_layer} downloaded as GPKG\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing layer {layer}: {e}\")\n",
    "\n",
    "print(f\"Downloaded {len(layer_list) - len(missing_layers)} layers as GPKG files\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suprimir advertencias\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='geopandas')\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning, module='pyogrio')\n",
    "\n",
    "# Create temporary directory\n",
    "tmp_dir = 'tmp_shapefile'\n",
    "os.makedirs(tmp_dir, exist_ok=True)\n",
    "\n",
    "# Download the layers as shapefiles and zip them\n",
    "print(\"Downloading layers...\")\n",
    "for layer in layer_list:\n",
    "    if layer_dict[layer] not in available_layers:\n",
    "        continue\n",
    "    try:\n",
    "        response = wfs.getfeature(typename=layer_dict[layer], outputFormat=\"json\")\n",
    "        gdf = gpd.read_file(response)\n",
    "        renamed_layer = rename_layer(layer)\n",
    "        # Save temporary shapefile\n",
    "        layer_tmp_dir = os.path.join(tmp_dir, renamed_layer)\n",
    "        os.makedirs(layer_tmp_dir, exist_ok=True)\n",
    "        gdf.to_file(f\"{layer_tmp_dir}/{renamed_layer}.shp\")\n",
    "        print(f\"{renamed_layer} downloaded as shapefile\")\n",
    "\n",
    "        # Zip the shapefile\n",
    "        shapefile_zip = os.path.join(output_dir, f\"{renamed_layer}.zip\")\n",
    "        with zipfile.ZipFile(shapefile_zip, 'w') as zipf:\n",
    "            for root, dirs, files in os.walk(layer_tmp_dir):\n",
    "                for file in files:\n",
    "                    zipf.write(os.path.join(root, file), os.path.relpath(os.path.join(root, file), layer_tmp_dir))\n",
    "\n",
    "        print(f\"{renamed_layer} shapefile zipped as {shapefile_zip}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing layer {layer}: {e}\")\n",
    "\n",
    "# Clean up temporary directory\n",
    "shutil.rmtree(tmp_dir)\n",
    "\n",
    "print(f\"Downloaded and zipped {len(layer_list) - len(missing_layers)} layers\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
